"""
ä¸»ç¨‹åºæ¨¡å—
åŠŸèƒ½ï¼šä¸²è”æ•´ä¸ªæ•°æ®æŒ–æ˜æµç¨‹ï¼Œè¾“å‡ºä¸»è¦ç»“æœä¸å¯è§†åŒ–å›¾è¡¨
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_preprocessing import LoanDataPreprocessor
from clustering_analysis import LoanClusteringAnalyzer
from association_rules_simple import LoanAssociationAnalyzer

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class LoanDataMiningPipeline:
    """è´·æ¬¾æ•°æ®æŒ–æ˜å®Œæ•´æµç¨‹"""
    
    def __init__(self, data_path):
        """
        åˆå§‹åŒ–æ•°æ®æŒ–æ˜æµç¨‹
        
        Args:
            data_path (str): æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.data_path = data_path
        self.preprocessor = None
        self.clustering_analyzer = None
        self.association_analyzer = None
        self.results = {}
        
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®æŒ–æ˜åˆ†ææµç¨‹"""
        print("=" * 60)
        print("è´·æ¬¾å®¡æ‰¹æ•°æ®æŒ–æ˜åˆ†æç³»ç»Ÿ")
        print("=" * 60)
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®é¢„å¤„ç†
        print("ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®é¢„å¤„ç†")
        print("-" * 30)
        self._run_preprocessing()
        
        # ç¬¬äºŒé˜¶æ®µï¼šèšç±»åˆ†æ
        print("\nç¬¬äºŒé˜¶æ®µï¼šèšç±»åˆ†æ")
        print("-" * 30)
        self._run_clustering()
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šå…³è”è§„åˆ™åˆ†æ
        print("\nç¬¬ä¸‰é˜¶æ®µï¼šå…³è”è§„åˆ™åˆ†æ")
        print("-" * 30)
        self._run_association_rules()
        
        # ç¬¬å››é˜¶æ®µï¼šç»“æœæ±‡æ€»
        print("\nç¬¬å››é˜¶æ®µï¼šç»“æœæ±‡æ€»")
        print("-" * 30)
        self._summarize_results()
        
        print(f"\nåˆ†æå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        return self.results
    
    def _run_preprocessing(self):
        """è¿è¡Œæ•°æ®é¢„å¤„ç†"""
        print("æ­£åœ¨æ‰§è¡Œæ•°æ®é¢„å¤„ç†...")
        
        # åˆ›å»ºé¢„å¤„ç†å™¨
        self.preprocessor = LoanDataPreprocessor(self.data_path)
        
        # è¿è¡Œé¢„å¤„ç†
        X, y, raw_data = self.preprocessor.run_preprocessing()
        
        # ä¿å­˜ç»“æœ
        self.results['preprocessing'] = {
            'X': X,
            'y': y,
            'raw_data': raw_data,
            'feature_names': X.columns.tolist(),
            'data_shape': X.shape,
            'target_distribution': y.value_counts().to_dict()
        }
        
        print("æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
    
    def _run_clustering(self):
        """è¿è¡Œèšç±»åˆ†æ"""
        print("æ­£åœ¨æ‰§è¡Œèšç±»åˆ†æ...")
        
        if self.preprocessor is None:
            raise ValueError("è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†ï¼")
        
        X = self.results['preprocessing']['X']
        y = self.results['preprocessing']['y']
        
        # åˆ›å»ºèšç±»åˆ†æå™¨
        self.clustering_analyzer = LoanClusteringAnalyzer(X, y)
        
        # è¿è¡Œèšç±»åˆ†æ
        cluster_data, k_results = self.clustering_analyzer.run_clustering_analysis()
        
        # ä¿å­˜ç»“æœ
        self.results['clustering'] = {
            'cluster_data': cluster_data,
            'k_results': k_results,
            'optimal_k': self.clustering_analyzer.optimal_k,
            'cluster_labels': self.clustering_analyzer.cluster_labels,
            'silhouette_score': silhouette_score(X, self.clustering_analyzer.cluster_labels) if self.clustering_analyzer.cluster_labels is not None else None
        }
        
        print("èšç±»åˆ†æå®Œæˆï¼")
    
    def _run_association_rules(self):
        """è¿è¡Œå…³è”è§„åˆ™åˆ†æ"""
        print("æ­£åœ¨æ‰§è¡Œå…³è”è§„åˆ™åˆ†æ...")
        
        if self.preprocessor is None:
            raise ValueError("è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†ï¼")
        
        raw_data = self.results['preprocessing']['raw_data']
        
        # åˆ›å»ºå…³è”è§„åˆ™åˆ†æå™¨
        self.association_analyzer = LoanAssociationAnalyzer(raw_data)
        
        # è¿è¡Œå…³è”è§„åˆ™åˆ†æ
        rules, approval_rules = self.association_analyzer.run_association_analysis()
        
        # ä¿å­˜ç»“æœ
        self.results['association_rules'] = {
            'all_rules': rules,
            'approval_rules': approval_rules,
            'rules_count': len(rules) if rules is not None else 0,
            'approval_rules_count': len(approval_rules) if approval_rules is not None else 0
        }
        
        print("å…³è”è§„åˆ™åˆ†æå®Œæˆï¼")
    
    def _summarize_results(self):
        """æ±‡æ€»åˆ†æç»“æœ"""
        print("æ­£åœ¨æ±‡æ€»åˆ†æç»“æœ...")
        
        # åˆ›å»ºç»“æœæ±‡æ€»æŠ¥å‘Š
        summary = {
            'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'data_info': {},
            'clustering_summary': {},
            'association_rules_summary': {},
            'key_insights': []
        }
        
        # æ•°æ®ä¿¡æ¯æ±‡æ€»
        if 'preprocessing' in self.results:
            prep_results = self.results['preprocessing']
            summary['data_info'] = {
                'total_samples': prep_results['data_shape'][0],
                'total_features': prep_results['data_shape'][1],
                'approval_rate': prep_results['target_distribution'].get(True, 0) / 
                               sum(prep_results['target_distribution'].values()),
                'feature_names': prep_results['feature_names']
            }
        
        # èšç±»åˆ†ææ±‡æ€»
        if 'clustering' in self.results:
            cluster_results = self.results['clustering']
            summary['clustering_summary'] = {
                'optimal_clusters': cluster_results['optimal_k'],
                'silhouette_score': cluster_results['silhouette_score'],
                'cluster_distribution': np.bincount(cluster_results['cluster_labels']).tolist()
            }
        
        # å…³è”è§„åˆ™æ±‡æ€»
        if 'association_rules' in self.results:
            ar_results = self.results['association_rules']
            summary['association_rules_summary'] = {
                'total_rules': ar_results['rules_count'],
                'approval_related_rules': ar_results['approval_rules_count']
            }
        
        # å…³é”®æ´å¯Ÿ
        self._generate_key_insights(summary)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        self.results['summary'] = summary
        
        # æ‰“å°æ±‡æ€»æŠ¥å‘Š
        self._print_summary_report(summary)
        
        # åˆ›å»ºç»¼åˆå¯è§†åŒ–
        self._create_comprehensive_visualization()
    
    def _generate_key_insights(self, summary):
        """ç”Ÿæˆå…³é”®æ´å¯Ÿ"""
        insights = []
        
        # åŸºäºæ•°æ®ä¿¡æ¯çš„æ´å¯Ÿ
        if 'data_info' in summary:
            data_info = summary['data_info']
            approval_rate = data_info['approval_rate']
            
            if approval_rate < 0.3:
                insights.append(f"è´·æ¬¾æ‰¹å‡†ç‡è¾ƒä½ ({approval_rate:.1%})ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨å®¡æ‰¹æ ‡å‡†")
            elif approval_rate > 0.7:
                insights.append(f"è´·æ¬¾æ‰¹å‡†ç‡è¾ƒé«˜ ({approval_rate:.1%})ï¼Œå®¡æ‰¹æ ‡å‡†å¯èƒ½è¾ƒä¸ºå®½æ¾")
            else:
                insights.append(f"è´·æ¬¾æ‰¹å‡†ç‡é€‚ä¸­ ({approval_rate:.1%})ï¼Œå®¡æ‰¹æ ‡å‡†ç›¸å¯¹å¹³è¡¡")
        
        # åŸºäºèšç±»åˆ†æçš„æ´å¯Ÿ
        if 'clustering_summary' in summary:
            cluster_summary = summary['clustering_summary']
            optimal_k = cluster_summary['optimal_clusters']
            silhouette_score = cluster_summary['silhouette_score']
            
            if silhouette_score > 0.5:
                insights.append(f"èšç±»æ•ˆæœè‰¯å¥½ (Silhouette Score: {silhouette_score:.3f})ï¼Œå®¢æˆ·ç¾¤ä½“ç‰¹å¾æ˜æ˜¾")
            else:
                insights.append(f"èšç±»æ•ˆæœä¸€èˆ¬ (Silhouette Score: {silhouette_score:.3f})ï¼Œå®¢æˆ·ç¾¤ä½“ç‰¹å¾ä¸å¤Ÿæ˜æ˜¾")
            
            insights.append(f"å»ºè®®å°†å®¢æˆ·åˆ†ä¸º {optimal_k} ä¸ªç¾¤ä½“è¿›è¡Œå·®å¼‚åŒ–æœåŠ¡")
        
        # åŸºäºå…³è”è§„åˆ™çš„æ´å¯Ÿ
        if 'association_rules_summary' in summary:
            ar_summary = summary['association_rules_summary']
            total_rules = ar_summary['total_rules']
            approval_rules = ar_summary['approval_related_rules']
            
            if approval_rules > 0:
                insights.append(f"å‘ç° {approval_rules} æ¡ä¸è´·æ¬¾å®¡æ‰¹ç›¸å…³çš„å…³è”è§„åˆ™ï¼Œå¯ç”¨äºä¼˜åŒ–å®¡æ‰¹æµç¨‹")
            else:
                insights.append("æœªå‘ç°æ˜æ˜¾çš„è´·æ¬¾å®¡æ‰¹å…³è”è§„åˆ™ï¼Œå»ºè®®è°ƒæ•´å‚æ•°é‡æ–°åˆ†æ")
        
        summary['key_insights'] = insights
    
    def _print_summary_report(self, summary):
        """æ‰“å°æ±‡æ€»æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("åˆ†æç»“æœæ±‡æ€»æŠ¥å‘Š")
        print("=" * 60)
        
        # æ•°æ®æ¦‚è§ˆ
        if 'data_info' in summary:
            data_info = summary['data_info']
            print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
            print(f"   â€¢ æ€»æ ·æœ¬æ•°: {data_info['total_samples']:,}")
            print(f"   â€¢ ç‰¹å¾æ•°é‡: {data_info['total_features']}")
            print(f"   â€¢ è´·æ¬¾æ‰¹å‡†ç‡: {data_info['approval_rate']:.1%}")
        
        # èšç±»åˆ†æç»“æœ
        if 'clustering_summary' in summary:
            cluster_summary = summary['clustering_summary']
            print(f"\nğŸ” èšç±»åˆ†æç»“æœ:")
            print(f"   â€¢ æœ€ä½³èšç±»æ•°: {cluster_summary['optimal_clusters']}")
            print(f"   â€¢ èšç±»è´¨é‡ (Silhouette Score): {cluster_summary['silhouette_score']:.3f}")
            print(f"   â€¢ å„èšç±»æ ·æœ¬åˆ†å¸ƒ: {cluster_summary['cluster_distribution']}")
        
        # å…³è”è§„åˆ™ç»“æœ
        if 'association_rules_summary' in summary:
            ar_summary = summary['association_rules_summary']
            print(f"\nğŸ”— å…³è”è§„åˆ™åˆ†æç»“æœ:")
            print(f"   â€¢ æ€»è§„åˆ™æ•°: {ar_summary['total_rules']}")
            print(f"   â€¢ å®¡æ‰¹ç›¸å…³è§„åˆ™æ•°: {ar_summary['approval_related_rules']}")
        
        # å…³é”®æ´å¯Ÿ
        if 'key_insights' in summary:
            print(f"\nğŸ’¡ å…³é”®æ´å¯Ÿ:")
            for i, insight in enumerate(summary['key_insights'], 1):
                print(f"   {i}. {insight}")
        
        print("\n" + "=" * 60)
    
    def _create_comprehensive_visualization(self):
        """åˆ›å»ºç»¼åˆå¯è§†åŒ–"""
        print("æ­£åœ¨åˆ›å»ºç»¼åˆå¯è§†åŒ–...")
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        fig.suptitle('è´·æ¬¾å®¡æ‰¹æ•°æ®æŒ–æ˜åˆ†æç»¼åˆæŠ¥å‘Š', fontsize=16, fontweight='bold')
        
        # 1. è´·æ¬¾å®¡æ‰¹åˆ†å¸ƒ
        if 'preprocessing' in self.results:
            y = self.results['preprocessing']['y']
            approval_counts = y.value_counts()
            axes[0,0].pie(approval_counts.values, labels=['æ‹’ç»', 'æ‰¹å‡†'], autopct='%1.1f%%', 
                         colors=['lightcoral', 'lightgreen'])
            axes[0,0].set_title('è´·æ¬¾å®¡æ‰¹åˆ†å¸ƒ')
        
        # 2. èšç±»ç»“æœ
        if 'clustering' in self.results:
            cluster_labels = self.results['clustering']['cluster_labels']
            if cluster_labels is not None:
                unique, counts = np.unique(cluster_labels, return_counts=True)
                axes[0,1].bar(unique, counts, color='skyblue', alpha=0.7)
                axes[0,1].set_title('èšç±»åˆ†å¸ƒ')
                axes[0,1].set_xlabel('èšç±»ç¼–å·')
                axes[0,1].set_ylabel('æ ·æœ¬æ•°é‡')
        
        # 3. ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºæ–¹å·®ï¼‰
        if 'preprocessing' in self.results:
            X = self.results['preprocessing']['X']
            feature_vars = X.var().sort_values(ascending=True)
            axes[0,2].barh(range(len(feature_vars)), feature_vars.values)
            axes[0,2].set_yticks(range(len(feature_vars)))
            axes[0,2].set_yticklabels(feature_vars.index)
            axes[0,2].set_title('ç‰¹å¾æ–¹å·®åˆ†å¸ƒ')
            axes[0,2].set_xlabel('æ–¹å·®')
        
        # 4. æ”¶å…¥ä¸ä¿¡ç”¨è¯„åˆ†å…³ç³»
        if 'preprocessing' in self.results:
            raw_data = self.results['preprocessing']['raw_data']
            scatter = axes[1,0].scatter(raw_data['income'], raw_data['credit_score'], 
                                      c=raw_data['loan_approved'].astype(int), 
                                      alpha=0.6, cmap='RdYlGn')
            axes[1,0].set_title('æ”¶å…¥ vs ä¿¡ç”¨è¯„åˆ†')
            axes[1,0].set_xlabel('æ”¶å…¥')
            axes[1,0].set_ylabel('ä¿¡ç”¨è¯„åˆ†')
        
        # 5. å…³è”è§„åˆ™è´¨é‡åˆ†å¸ƒ
        if 'association_rules' in self.results:
            rules = self.results['association_rules']['all_rules']
            if rules is not None and len(rules) > 0:
                axes[1,1].scatter(rules['support'], rules['confidence'], 
                                c=rules['lift'], cmap='viridis', alpha=0.6)
                axes[1,1].set_title('å…³è”è§„åˆ™è´¨é‡åˆ†å¸ƒ')
                axes[1,1].set_xlabel('æ”¯æŒåº¦')
                axes[1,1].set_ylabel('ç½®ä¿¡åº¦')
                cbar = plt.colorbar(axes[1,1].collections[0], ax=axes[1,1])
                cbar.set_label('æå‡åº¦')
        
        # 6. åˆ†ææ—¶é—´è½´
        analysis_steps = ['æ•°æ®é¢„å¤„ç†', 'èšç±»åˆ†æ', 'å…³è”è§„åˆ™åˆ†æ', 'ç»“æœæ±‡æ€»']
        step_times = [1, 2, 3, 4]  # æ¨¡æ‹Ÿæ—¶é—´
        axes[1,2].plot(step_times, analysis_steps, 'o-', linewidth=2, markersize=8)
        axes[1,2].set_title('åˆ†ææµç¨‹æ—¶é—´è½´')
        axes[1,2].set_xlabel('æ­¥éª¤')
        axes[1,2].set_ylabel('åˆ†æé˜¶æ®µ')
        axes[1,2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def save_results(self, output_path='loan_analysis_results.xlsx'):
        """ä¿å­˜åˆ†æç»“æœåˆ°Excelæ–‡ä»¶"""
        print(f"æ­£åœ¨ä¿å­˜ç»“æœåˆ° {output_path}...")
        
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # ä¿å­˜åŸå§‹æ•°æ®
            if 'preprocessing' in self.results:
                self.results['preprocessing']['raw_data'].to_excel(
                    writer, sheet_name='åŸå§‹æ•°æ®', index=False)
                
                # ä¿å­˜é¢„å¤„ç†åçš„ç‰¹å¾æ•°æ®
                feature_data = self.results['preprocessing']['X'].copy()
                feature_data['loan_approved'] = self.results['preprocessing']['y']
                feature_data.to_excel(writer, sheet_name='é¢„å¤„ç†æ•°æ®', index=False)
            
            # ä¿å­˜èšç±»ç»“æœ
            if 'clustering' in self.results:
                self.results['clustering']['cluster_data'].to_excel(
                    writer, sheet_name='èšç±»ç»“æœ', index=False)
            
            # ä¿å­˜å…³è”è§„åˆ™
            if 'association_rules' in self.results:
                rules = self.results['association_rules']['all_rules']
                if rules is not None and len(rules) > 0:
                    rules.to_excel(writer, sheet_name='å…³è”è§„åˆ™', index=False)
        
        print(f"ç»“æœå·²ä¿å­˜åˆ° {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºæ•°æ®æŒ–æ˜æµç¨‹
    pipeline = LoanDataMiningPipeline('loan_approval.csv')
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    results = pipeline.run_complete_analysis()
    
    # ä¿å­˜ç»“æœ
    pipeline.save_results()
    
    return pipeline, results

if __name__ == "__main__":
    pipeline, results = main()
